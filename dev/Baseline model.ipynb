{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f53f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "project_dir = os.getcwd()\n",
    "data_dir = os.path.join(project_dir, \"data\")\n",
    "model_dir = os.path.join(project_dir, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1b27ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.max_colwidth = 255\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d5a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = joblib.load(f\"{data_dir}/x_train.pkl\")\n",
    "X_val = joblib.load(f\"{data_dir}/x_val.pkl\")\n",
    "y_train = joblib.load(f\"{data_dir}/y_train.pkl\")\n",
    "y_val = joblib.load(f\"{data_dir}/y_val.pkl\")\n",
    "y_classes = joblib.load(f\"{data_dir}/y_classes.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c8fd79",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c978fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sotir\\anaconda3\\envs\\thesis-pytorch\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:26:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:26:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:30:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:30:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:32:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:32:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:34:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:34:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:36:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:36:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:38:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:38:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:40:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:40:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:42:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:42:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:45:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:47:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:47:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:49:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:49:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:53:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:55:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:55:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:57:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:57:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:59:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:59:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:02:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:02:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:04:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:04:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"num_round\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:06:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=10,\n",
       "                                            enable_categorical=False, eta=0.2,\n",
       "                                            gamma=4, gpu_id=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=5,\n",
       "                                            min_child_weight=6, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            num_round=200, predictor=None,\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=0.8, tree_method=None,\n",
       "                                            validate_parameters=None, ...))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_classifier = XGBClassifier(max_depth=5,\n",
    "                               eta=0.2,\n",
    "                               gamma=4,\n",
    "                               min_child_weight=6,\n",
    "                               subsample=0.8,\n",
    "                               early_stopping_rounds=10,\n",
    "                               num_round=200,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "clf = OneVsRestClassifier(xgb_classifier)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d79e4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\sotir\\\\Documents\\\\git\\\\satori-case-study\\\\model/one_vs_rest_classifier.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, f\"{model_dir}/one_vs_rest_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9004b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(f\"{model_dir}/one_vs_rest_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a1ca771",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c536c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\sotir\\\\Documents\\\\git\\\\satori-case-study\\\\model/y_pred.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred, f\"{model_dir}/y_pred.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08801bb6",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2765a3",
   "metadata": {},
   "source": [
    "#### Precision, Recall, F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8385175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eacdef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.68735806 0.97493509 0.95869614 0.84954312 0.89045074 0.9007286\n",
      " 0.94295369 0.85416667 0.70720175 0.83797702 0.76610542 0.92309581\n",
      " 0.7852476  0.87271538 0.88250465 0.67351547 0.92669097 0.97412418\n",
      " 0.96672764 0.80987912]\n",
      "recall: [0.07576769 0.85819141 0.84436142 0.45759169 0.6618028  0.60712093\n",
      " 0.60129283 0.6827174  0.41653931 0.65934488 0.38798777 0.65492492\n",
      " 0.62211759 0.71395094 0.69431861 0.44071803 0.78644506 0.86139312\n",
      " 0.85918873 0.60977528]\n",
      "fscore: [0.13649004 0.91284581 0.89790371 0.59480303 0.75928678 0.7253392\n",
      " 0.73432743 0.7588789  0.52427973 0.73800544 0.5151049  0.76622371\n",
      " 0.69422826 0.78539005 0.77718209 0.5327975  0.8508274  0.91429688\n",
      " 0.90979138 0.69572463]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(y_val, y_pred)\n",
    "\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"fscore: {fscore}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea699b37",
   "metadata": {},
   "source": [
    "#### Hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff1c4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "hamming = []\n",
    "\n",
    "for i, (test, pred) in enumerate(zip(y_val.T, y_pred.T)):\n",
    "    hamming.append(hamming_loss(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfd6b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = pd.DataFrame(data=[precision, recall, fscore, hamming],\n",
    "                         index=[\"Precision\", \"Recall\", \"F-1 score\", \"Hamming loss\"],\n",
    "                         columns=y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e0a03e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.net</th>\n",
       "      <th>android</th>\n",
       "      <th>angularjs</th>\n",
       "      <th>asp.net</th>\n",
       "      <th>c</th>\n",
       "      <th>c#</th>\n",
       "      <th>c++</th>\n",
       "      <th>css</th>\n",
       "      <th>html</th>\n",
       "      <th>ios</th>\n",
       "      <th>iphone</th>\n",
       "      <th>java</th>\n",
       "      <th>javascript</th>\n",
       "      <th>jquery</th>\n",
       "      <th>mysql</th>\n",
       "      <th>objective-c</th>\n",
       "      <th>php</th>\n",
       "      <th>python</th>\n",
       "      <th>ruby-on-rails</th>\n",
       "      <th>sql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.687358</td>\n",
       "      <td>0.974935</td>\n",
       "      <td>0.958696</td>\n",
       "      <td>0.849543</td>\n",
       "      <td>0.890451</td>\n",
       "      <td>0.900729</td>\n",
       "      <td>0.942954</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.707202</td>\n",
       "      <td>0.837977</td>\n",
       "      <td>0.766105</td>\n",
       "      <td>0.923096</td>\n",
       "      <td>0.785248</td>\n",
       "      <td>0.872715</td>\n",
       "      <td>0.882505</td>\n",
       "      <td>0.673515</td>\n",
       "      <td>0.926691</td>\n",
       "      <td>0.974124</td>\n",
       "      <td>0.966728</td>\n",
       "      <td>0.809879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.075768</td>\n",
       "      <td>0.858191</td>\n",
       "      <td>0.844361</td>\n",
       "      <td>0.457592</td>\n",
       "      <td>0.661803</td>\n",
       "      <td>0.607121</td>\n",
       "      <td>0.601293</td>\n",
       "      <td>0.682717</td>\n",
       "      <td>0.416539</td>\n",
       "      <td>0.659345</td>\n",
       "      <td>0.387988</td>\n",
       "      <td>0.654925</td>\n",
       "      <td>0.622118</td>\n",
       "      <td>0.713951</td>\n",
       "      <td>0.694319</td>\n",
       "      <td>0.440718</td>\n",
       "      <td>0.786445</td>\n",
       "      <td>0.861393</td>\n",
       "      <td>0.859189</td>\n",
       "      <td>0.609775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-1 score</th>\n",
       "      <td>0.136490</td>\n",
       "      <td>0.912846</td>\n",
       "      <td>0.897904</td>\n",
       "      <td>0.594803</td>\n",
       "      <td>0.759287</td>\n",
       "      <td>0.725339</td>\n",
       "      <td>0.734327</td>\n",
       "      <td>0.758879</td>\n",
       "      <td>0.524280</td>\n",
       "      <td>0.738005</td>\n",
       "      <td>0.515105</td>\n",
       "      <td>0.766224</td>\n",
       "      <td>0.694228</td>\n",
       "      <td>0.785390</td>\n",
       "      <td>0.777182</td>\n",
       "      <td>0.532797</td>\n",
       "      <td>0.850827</td>\n",
       "      <td>0.914297</td>\n",
       "      <td>0.909791</td>\n",
       "      <td>0.695725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hamming loss</th>\n",
       "      <td>0.027002</td>\n",
       "      <td>0.017526</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.021732</td>\n",
       "      <td>0.011422</td>\n",
       "      <td>0.054570</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.021493</td>\n",
       "      <td>0.052311</td>\n",
       "      <td>0.025796</td>\n",
       "      <td>0.018522</td>\n",
       "      <td>0.053914</td>\n",
       "      <td>0.079872</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.019829</td>\n",
       "      <td>0.024590</td>\n",
       "      <td>0.032055</td>\n",
       "      <td>0.012374</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.022313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  .net   android  angularjs   asp.net         c        c#  \\\n",
       "Precision     0.687358  0.974935   0.958696  0.849543  0.890451  0.900729   \n",
       "Recall        0.075768  0.858191   0.844361  0.457592  0.661803  0.607121   \n",
       "F-1 score     0.136490  0.912846   0.897904  0.594803  0.759287  0.725339   \n",
       "Hamming loss  0.027002  0.017526   0.004590  0.021732  0.011422  0.054570   \n",
       "\n",
       "                   c++       css      html       ios    iphone      java  \\\n",
       "Precision     0.942954  0.854167  0.707202  0.837977  0.766105  0.923096   \n",
       "Recall        0.601293  0.682717  0.416539  0.659345  0.387988  0.654925   \n",
       "F-1 score     0.734327  0.758879  0.524280  0.738005  0.515105  0.766224   \n",
       "Hamming loss  0.024202  0.021493  0.052311  0.025796  0.018522  0.053914   \n",
       "\n",
       "              javascript    jquery     mysql  objective-c       php    python  \\\n",
       "Precision       0.785248  0.872715  0.882505     0.673515  0.926691  0.974124   \n",
       "Recall          0.622118  0.713951  0.694319     0.440718  0.786445  0.861393   \n",
       "F-1 score       0.694228  0.785390  0.777182     0.532797  0.850827  0.914297   \n",
       "Hamming loss    0.079872  0.036001  0.019829     0.024590  0.032055  0.012374   \n",
       "\n",
       "              ruby-on-rails       sql  \n",
       "Precision          0.966728  0.809879  \n",
       "Recall             0.859189  0.609775  \n",
       "F-1 score          0.909791  0.695725  \n",
       "Hamming loss       0.005173  0.022313  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
